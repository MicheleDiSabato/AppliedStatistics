cbind(m1 - m)
B
# covariance within groups (estimate)
Sp
# how many coordinates?
g <- 3
p <- 2
s <- min(g-1,p)
s
dim(Sp)
dim(B)
# Matrix Sp^(-1/2)
val.Sp <- eigen(Sp)$val
vec.Sp <- eigen(Sp)$vec
vec.Sp
invSp.2 <- 1/sqrt(val.Sp[1])*vec.Sp[,1]%*%t(vec.Sp[,1]) + 1/sqrt(val.Sp[2])*vec.Sp[,2]%*%t(vec.Sp[,2])
invSp.2
# spectral decomposition of Sp^(-1/2) B Sp^(-1/2)
spec.dec <- eigen(invSp.2 %*% B %*% invSp.2)
# first canonical coordinate
a1 <- invSp.2 %*% spec.dec$vec[,1]
a1
# second canonical coordinate
a2 <- invSp.2 %*% spec.dec$vec[,2]
a2
# compare with the output of lda():
lda.iris
a1
a2
spec.dec$val/sum(spec.dec$val)
# compare with the output of lda():
lda.iris
a1
cc1.iris <- as.matrix(iris2)%*%a1
cc2.iris <- as.matrix(iris2)%*%a2
coord.cc <- cbind(cc1.iris,cc2.iris)
# Compute the coordinates of the mean within groups along the canonical directions
cc.m1 <- c(m1%*%a1, m1%*%a2)
cc.m2 <- c(m2%*%a1, m2%*%a2)
cc.m3 <- c(m3%*%a1, m3%*%a2)
# compare with the output of lda():
lda.iris
a1
a2
spec.dec$val/sum(spec.dec$val)
cc1.iris <- as.matrix(iris2)%*%a1
cc2.iris <- as.matrix(iris2)%*%a2
coord.cc <- cbind(cc1.iris,cc2.iris)
# Compute the coordinates of the mean within groups along the canonical directions
cc.m1 <- c(m1%*%a1, m1%*%a2)
cc.m2 <- c(m2%*%a1, m2%*%a2)
cc.m3 <- c(m3%*%a1, m3%*%a2)
# Assign data to groups
f.class=rep(0, n)
for(i in 1:n) # for each datum
{
# Compute the Euclidean distance of the i-th datum from mean within the groups
dist.m=c(d1=sqrt(sum((coord.cc[i,]-cc.m1)^2)),
d2=sqrt(sum((coord.cc[i,]-cc.m2)^2)),
d3=sqrt(sum((coord.cc[i,]-cc.m3)^2)))
# Assign the datum to the group whose mean is the nearest
f.class[i]=which.min(dist.m)
}
f.class
table(class.true=species.name, class.assigned=f.class)
errors <- 150 - sum(diag(table(class.true=species.name, class.assigned=f.class)))
errors
length(species.name)
1+14+15
APERf   <- errors/length(species.name)
APERf
### How do I classify a new observation?
x.new <- c(5.85, 2.90)
# compute the canonical coordinates
cc.new <- c(x.new%*%a1, x.new%*%a2)
# compute the distance from the means
dist.m <- c(d1=sqrt(sum((cc.new-cc.m1)^2)),
d2=sqrt(sum((cc.new-cc.m2)^2)),
d3=sqrt(sum((cc.new-cc.m3)^2)))
# assign to the nearest mean
which.min(dist.m)
color.species=rep(c('red','green','blue'), each=50)
# visually
x11(width=14, height=7)
par(mfrow=c(1,2))
plot(iris2[,1], iris2[,2], main='Plane of original coordinates',
xlab='Sepal.Length', ylab='Sepal.Width', pch=20, col=as.character(color.species))
legend("topleft", legend=levels(species.name), fill=c('red','green','blue'), cex=.7)
points(x.new[1], x.new[2], col='gold', pch=19)
points(m1[1], m1[2], pch=4,col='red' , lwd=2, cex=1.5)
points(m2[1], m2[2], pch=4,col='green' , lwd=2, cex=1.5)
points(m3[1], m3[2], pch=4,col='blue' , lwd=2, cex=1.5)
plot(cc1.iris, cc2.iris, main='Plane of canonical coordinates', xlab='first canonical coordinate', ylab='second canonical coordinate', pch=20, col=as.character(color.species))
legend("topleft", legend=levels(species.name), fill=c('red','green','blue'), cex=.7)
points(cc.m1[1], cc.m1[2], pch=4,col='red' , lwd=2, cex=1.5)
points(cc.m2[1], cc.m2[2], pch=4,col='green' , lwd=2, cex=1.5)
points(cc.m3[1], cc.m3[2], pch=4,col='blue' , lwd=2, cex=1.5)
points(cc.new[1], cc.new[2], col='gold', pch=19)
segments(cc.m1[1], cc.m1[2], cc.new[1], cc.new[2])
segments(cc.m2[1], cc.m2[2], cc.new[1], cc.new[2])
segments(cc.m3[1], cc.m3[2], cc.new[1], cc.new[2])
### We plot the partition generated by the canonical coordinates
color.species <- species.name
levels(color.species) <- c('red','green','blue')
color.species
x11()
plot(cc1.iris, cc2.iris, main='Fisher discriminant analysis', xlab='first canonical coordinate', ylab='second canonical coordinate', pch=20, col=as.character(color.species))
legend("topleft", legend=levels(species.name), fill=c('red','green','blue'), cex=.7)
points(cc.m1[1], cc.m1[2], pch=4,col='red' , lwd=2, cex=1.5)
points(cc.m2[1], cc.m2[2], pch=4,col='green' , lwd=2, cex=1.5)
points(cc.m3[1], cc.m3[2], pch=4,col='blue' , lwd=2, cex=1.5)
x.cc  <- seq(min(cc1.iris),max(cc1.iris),len=200)
y.cc  <- seq(min(cc2.iris),max(cc2.iris),len=200)
xy.cc <- expand.grid(cc1=x.cc, cc2=y.cc)
z  <- cbind( sqrt(rowSums(scale(xy.cc,cc.m1,scale=FALSE)^2)), sqrt(rowSums(scale(xy.cc,cc.m2,scale=FALSE)^2)), sqrt(rowSums(scale(xy.cc,cc.m3,scale=FALSE)^2)))
z1.cc <- z[,1] - pmin(z[,2], z[,3])
z2.cc <- z[,2] - pmin(z[,1], z[,3])
z3.cc <- z[,3] - pmin(z[,1], z[,2])
contour(x.cc, y.cc, matrix(z1.cc, 200), levels=0, drawlabels=F, add=T)
contour(x.cc, y.cc, matrix(z2.cc, 200), levels=0, drawlabels=F, add=T)
contour(x.cc, y.cc, matrix(z3.cc, 200), levels=0, drawlabels=F, add=T)
x11()
plot(iris2, main='Iris Sepal', xlab='Sepal.Length', ylab='Sepal.Width', pch=20)
points(iris2[i1,], col='red', pch=20)
points(iris2[i2,], col='green', pch=20)
points(iris2[i3,], col='blue', pch=20)
legend("topright", legend=levels(species.name), fill=c('red','green','blue'), cex=.7)
points(rbind(m1,m2,m3), pch=4,col=c('red','green','blue') , lwd=2, cex=1.5)
x  <- seq(min(iris[,1]), max(iris[,1]), length=200)
y  <- seq(min(iris[,2]), max(iris[,2]), length=200)
xy <- expand.grid(Sepal.Length=x, Sepal.Width=y)
z  <- predict(lda.iris, xy)$post  # these are P_i*f_i(x,y)
z1 <- z[,1] - pmax(z[,2], z[,3])  # P_1*f_1(x,y)-max{P_j*f_j(x,y)}
z2 <- z[,2] - pmax(z[,1], z[,3])  # P_2*f_2(x,y)-max{P_j*f_j(x,y)}
z3 <- z[,3] - pmax(z[,1], z[,2])  # P_3*f_3(x,y)-max{P_j*f_j(x,y)}
# Plot the contour line of level (levels=0) of z1, z2, z3:
# where j realizes the max.
contour(x, y, matrix(z1, 200), levels=0, drawlabels=F, add=T)
contour(x, y, matrix(z2, 200), levels=0, drawlabels=F, add=T)
contour(x, y, matrix(z3, 200), levels=0, drawlabels=F, add=T)
x11()
plot(iris2, main='Projection on the canonical directions', xlab='Sepal.Length', ylab='Sepal.Width', pch=20, xlim=c(-3,8), ylim=c(-3,7))
points(iris2[i1,], col='red', pch=20)
points(iris2[i2,], col='green', pch=20)
points(iris2[i3,], col='blue', pch=20)
legend('topleft', legend=levels(species.name), fill=c('red','green','blue'), cex=.7)
points(rbind(m1,m2,m3), pch=4,col=c('red','green','blue') , lwd=2, cex=1.5)
abline(h=0,v=0, col='grey35')
arrows(x0=0, y0=0, x1=a1[1], y1=a1[2], length=.1)
arrows(x0=0, y0=0, x1=a2[1], y1=a2[2], length=.1)
text(a1[1], a1[2], 'a1',pos=3)
text(a2[1], a2[2], 'a2',pos=2)
abline(coef=c(0,(a1[2]/a1[1])), col='grey55',lty=2)
abline(coef=c(0,(a2[2]/a2[1])), col='grey55',lty=2)
points(cc1.iris*a1[1]/(sum(a1^2)),cc1.iris*a1[2]/(sum(a1^2)),col=as.character(color.species))
points(cc2.iris*a2[1]/(sum(a2^2)),cc2.iris*a2[2]/(sum(a2^2)),col=as.character(color.species))
x11()
plot(cc1.iris, cc2.iris, main='Coordinate system of the canonical coordinates', xlab='first canonical coordinate', ylab='second canonical coordinate', pch=20, col=as.character(color.species))
legend('topleft', legend=levels(species.name), fill=c('red','green','blue'), cex=.7)
x11()
plot(iris2, main='Projection on the canonical directions', xlab='Sepal.Length', ylab='Sepal.Width', pch=20, xlim=c(-3,8), ylim=c(-3,7))
points(iris2[i1,], col='red', pch=20)
points(iris2[i2,], col='green', pch=20)
points(iris2[i3,], col='blue', pch=20)
legend('topleft', legend=levels(species.name), fill=c('red','green','blue'), cex=.7)
points(rbind(m1,m2,m3), pch=4,col=c('red','green','blue') , lwd=2, cex=1.5)
abline(h=0,v=0, col='grey35')
arrows(x0=0, y0=0, x1=a1[1], y1=a1[2], length=.1)
arrows(x0=0, y0=0, x1=a2[1], y1=a2[2], length=.1)
text(a1[1], a1[2], 'a1',pos=3)
text(a2[1], a2[2], 'a2',pos=2)
abline(coef=c(0,(a1[2]/a1[1])), col='grey55',lty=2)
abline(coef=c(0,(a2[2]/a2[1])), col='grey55',lty=2)
points(cc1.iris*a1[1]/(sum(a1^2)),cc1.iris*a1[2]/(sum(a1^2)),col=as.character(color.species))
points(cc2.iris*a2[1]/(sum(a2^2)),cc2.iris*a2[2]/(sum(a2^2)),col=as.character(color.species))
x11()
plot(cc1.iris, cc2.iris, main='Coordinate system of the canonical coordinates', xlab='first canonical coordinate', ylab='second canonical coordinate', pch=20, col=as.character(color.species))
legend('topleft', legend=levels(species.name), fill=c('red','green','blue'), cex=.7)
cc.m1 <- c(m1%*%a1, m1%*%a2)
cc.m2 <- c(m2%*%a1, m2%*%a2)
cc.m3 <- c(m3%*%a1, m3%*%a2)
points(cc.m1[1], cc.m1[2], pch=4,col='red' , lwd=2, cex=1.5)
points(cc.m2[1], cc.m2[2], pch=4,col='green' , lwd=2, cex=1.5)
points(cc.m3[1], cc.m3[2], pch=4,col='blue' , lwd=2, cex=1.5)
graphics.off()
x11()
plot(iris2, main='Projection on the canonical directions', xlab='Sepal.Length', ylab='Sepal.Width', pch=20, xlim=c(-3,8), ylim=c(-3,7))
points(iris2[i1,], col='red', pch=20)
points(iris2[i2,], col='green', pch=20)
points(iris2[i3,], col='blue', pch=20)
legend('topleft', legend=levels(species.name), fill=c('red','green','blue'), cex=.7)
points(rbind(m1,m2,m3), pch=4,col=c('red','green','blue') , lwd=2, cex=1.5)
abline(h=0,v=0, col='grey35')
arrows(x0=0, y0=0, x1=a1[1], y1=a1[2], length=.1)
arrows(x0=0, y0=0, x1=a2[1], y1=a2[2], length=.1)
text(a1[1], a1[2], 'a1',pos=3)
text(a2[1], a2[2], 'a2',pos=2)
abline(coef=c(0,(a1[2]/a1[1])), col='grey55',lty=2)
abline(coef=c(0,(a2[2]/a2[1])), col='grey55',lty=2)
points(cc1.iris*a1[1]/(sum(a1^2)),cc1.iris*a1[2]/(sum(a1^2)),col=as.character(color.species))
points(cc2.iris*a2[1]/(sum(a2^2)),cc2.iris*a2[2]/(sum(a2^2)),col=as.character(color.species))
x11()
plot(cc1.iris, cc2.iris, main='Coordinate system of the canonical coordinates', xlab='first canonical coordinate', ylab='second canonical coordinate', pch=20, col=as.character(color.species))
legend('topleft', legend=levels(species.name), fill=c('red','green','blue'), cex=.7)
cc.m1 <- c(m1%*%a1, m1%*%a2)
cc.m2 <- c(m2%*%a1, m2%*%a2)
cc.m3 <- c(m3%*%a1, m3%*%a2)
points(cc.m1[1], cc.m1[2], pch=4,col='red' , lwd=2, cex=1.5)
points(cc.m2[1], cc.m2[2], pch=4,col='green' , lwd=2, cex=1.5)
points(cc.m3[1], cc.m3[2], pch=4,col='blue' , lwd=2, cex=1.5)
help(svm)
library(e1071)
help(svm)
# K-mean alignment
#
setwd("C:/Users/Michele/Desktop/POLIMI - MAGISTRALE/APPLIED STATISTCS/LAB_FDA")
load("C:/Users/Michele/Desktop/POLIMI - MAGISTRALE/APPLIED STATISTCS/LAB_5/mcshapiro.test.RData")
# Using the R package fdakma
library(fdakma)
help(kma)
help(kma.data)
data(kma.data)
names(kma.data)
x <- kma.data$x   # abscissas
y0 <- kma.data$y0 # evaluations of original functions
y1 <- kma.data$y1 # evaluations of original functions' first derivatives
# Plot of original functions
matplot(t(x),t(y0), type='l', xlab='x', ylab='orig.func')
title ('Original functions')
# Plot of original function first derivatives
matplot(t(x),t(y1), type='l', xlab='x', ylab='orig.deriv')
title ('Original function first derivatives')
set.seed(4)
fdakma_example_noalign_0der <- kma(
x=x, y0=y0, n.clust = 3,
warping.method = 'NOalignment',
similarity.method = 'd0.pearson',   # similarity computed as the cosine
# between the original curves
# (correlation)
center.method = 'k-means'
#,seeds = c(1,11,21) # you can give a little help to the algorithm...
)
kma.show.results(fdakma_example_noalign_0der)
set.seed(5)
fdakma_example_noalign_1der <- kma(
x=x, y0=y0, y1=y1, n.clust = 3,
warping.method = 'NOalignment',
similarity.method = 'd1.pearson',   # similarity computed as the cosine
# between the first derivatives
# (correlation)
center.method = 'k-means'
#,seeds = c(1,11,21) # you can give a little help to the algorithm...
)
kma.show.results(fdakma_example_noalign_1der)
table(fdakma_example_noalign_0der$labels,
fdakma_example_noalign_1der$labels, dnn=c("0der", "1der"))
set.seed(1)
fdakma_example <- kma(
x=x, y0=y0, y1=y1, n.clust = 2,
warping.method = 'affine',
similarity.method = 'd1.pearson',  # similarity computed as the cosine
# between the first derivatives
# (correlation)
center.method = 'k-means'
#seeds = c(1,21) # you can give a little help to the algorithm...
)
kma.show.results(fdakma_example)
# Labels assigned to each function
fdakma_example$labels
table(fdakma_example_noalign_0der$labels,
fdakma_example$labels,
dnn=c("NOalign_0der_3groups", "Align_1der_2groups"))
# Total shifts and dilations applied to the original
# abscissa to obtain the aligned abscissa
fdakma_example$shift
fdakma_example$dilation
plot(x, type="n", xlim=c(min(x),max(x)), ylim=c(min(x),max(x)+2), xlab="abscissa", ylab="warping")
title("Alignment affinities")
for(i in 1:30)(
abline(a=fdakma_example$shift[i],b=fdakma_example$dilation[i],
col=fdakma_example_noalign_0der$labels[i])
)
kma.show.results(fdakma_example)
kma.compare_example <- kma.compare (
x=x, y0=y0, y1=y1, n.clust = 1:3,
warping.method = c('affine'),
similarity.method = 'd1.pearson',
center.method = 'k-means',
seeds = c(1,21,30),
plot.graph=1)
plot(x, type="n", xlim=c(min(x),max(x)), ylim=c(min(x),max(x)+2), xlab="abscissa", ylab="warping")
title("Alignment affinities")
for(i in 1:30)(
abline(a=fdakma_example$shift[i],b=fdakma_example$dilation[i],
col=fdakma_example$labels[i])
)
graphics.off()
plot(x, type="n", xlim=c(min(x),max(x)), ylim=c(min(x),max(x)+2), xlab="abscissa", ylab="warping")
title("Alignment affinities")
for(i in 1:30)(
abline(a=fdakma_example$shift[i],b=fdakma_example$dilation[i],
col=fdakma_example$labels[i])
)
rm(list=ls())
graphics.off()
setwd("C:/Users/Michele/Desktop/POLIMI - MAGISTRALE/APPLIED STATISTCS/OLD_EXAMS/Old exams (in English)/200121")
load("C:/Users/Michele/Desktop/POLIMI - MAGISTRALE/APPLIED STATISTCS/LAB_5/mcshapiro.test.RData")
data <- read.table('', header=TRUE)
head(data)
# pdf(file = "myplot2.pdf", onefile = T)
# plot(rnorm(10),rnorm(10))
# plot(rnorm(10),rnorm(10))
# plot(rnorm(10),rnorm(10))
# dev.off()
#        ~
library(MASS)
library(car)
library(rgl)
library(mvtnorm)
library(glmnet)
library(mvnormtest)
library(rgl)
library(fda)
library(KernSmooth)
library(fdakma)
library(fields)
library(sp)           ## Data management
library(lattice)      ## Data management
library(geoR)         ## Geostatistics
library(gstat)        ## Geostatistics
library(e1071)
library(class)
# Problem n.4
# A satellite carrying an infrared spectrometer is collecting data of the surface of an asteroid in order to determine
# its chemical composition. The file spectra.txt reports the reflectance spectra of 10 independent measurements
# collected at different positions of the satellite along its orbit. Each spectrum has been sampled on the same grid of
# wavelengts (wl1,. . .,wl80). It is known that the spectrometer measurements are affected by small errors. Answer
# the following questions, considering a functional data analysis approach.
# a) Consider the first spectrum and perform a smoothing of this datum using a B-spline basis of degree 3. Choose
# the number of basis functions using a generalized cross-validation (GCV) criterion and provide a plot of the
# value of the GCV statistic versus the number of basis elements considered. Report the number of basis functions
# chosen and the first 3 coefficients of the basis expansion.
# b) Perform a smoothing of the other spectra using the basis chosen at point (a). Provide a plot of the smoothed
# data.
# c) Use the k-mean alignment algorithm to simultaneously cluster (k=3) and align the data allowing affine transformation for the abscissas. Use the correlation between the curves as similarity measure. Provide a plot of the
# aligned data colored according to the cluster assignment and a plot of the warping functions colored according
# to the cluster assignment. Comment on the results.
# a) Consider the first spectrum and perform a smoothing of this datum using a B-spline basis of degree 3. Choose
# the number of basis functions using a generalized cross-validation (GCV) criterion and provide a plot of the
# value of the GCV statistic versus the number of basis elements considered. Report the number of basis functions
# chosen and the first 3 coefficients of the basis expansion.
data <- read.table('spectra.txt', header=TRUE)
head(data)
Xobs0 <- as.numeric(data[1,])
abscissa <- 1:80
NT <- length(abscissa)
# plot(abscissa,Xobs0,xlab="t",ylab="observed data")
rappincX1 <- (Xobs0[3:NT]-Xobs0[1:(NT-2)])/(abscissa[3:NT]-abscissa[1:(NT-2)])
# par(mfrow=c(1,2),mar=c(6,5,2,1),mex=0.6, mgp=c(2.2,0.7,0),pty="m", font.main=1,font.lab=1, font.axis=1,cex.lab=1.3,cex.axis=1)
# plot(abscissa,Xobs0,xlab="t",ylab="observed data")
# plot(abscissa[2:(NT-1)],rappincX1,xlab="t",ylab="first differences x",type="l")
# dev.off()
m <- 4           # spline order
degree <- m-1    # spline degree
nbasis <- 4:30
gcv <- numeric(length(nbasis))
for (i in 1:length(nbasis)){
basis <- create.bspline.basis(range(abscissa), nbasis[i], m)
gcv[i] <- smooth.basis(abscissa, Xobs0, basis)$gcv
}
par(mfrow=c(1,1))
plot(nbasis,gcv)
nbasis[which.min(gcv)]
basis <- create.bspline.basis(range(abscissa), nbasis[which.min(gcv)], m)
basismat <- eval.basis(abscissa, basis)
basismat
lsfit(basismat, Xobs0, intercept=FALSE)$coef
# b) Perform a smoothing of the other spectra using the basis chosen at point (a). Provide a plot of the smoothed
# data.
Xsp0 <- basismat %*% lsfit(basismat, Xobs0, intercept=FALSE)$coef
# plot(abscissa,Xobs0,xlab="t",ylab="observed data")
# points(abscissa,Xsp0 ,type="l",col="blue",lwd=2)
# abline(v=basis$params) # numbasis  - m
par(mfrow=c(3,3))
for (i in 2:10)
{
Xobs0 <- as.numeric(data[i,])
abscissa <- 1:80
NT <- length(abscissa)
basismat <- eval.basis(abscissa, basis)
Xsp0 <- basismat %*% lsfit(basismat, Xobs0, intercept=FALSE)$coef
plot(abscissa,Xobs0,xlab="t",ylab="observed data",main=i)
points(abscissa,Xsp0 ,type="l",col="blue",lwd=2)
}
set.seed(1)
y0 = Xobs0
x = abscissa
fdakma_example <- kma(
x=abscissa, y0=data, n.clust = 3,
warping.method = 'affine',
similarity.method = 'd0.pearson',  # similarity computed as the cosine
# between the first derivatives
# (correlation)
center.method = 'k-means'
#seeds = c(1,21) # you can give a little help to the algorithm...
)
kma.show.results(fdakma_example)
graphics.off()
data <- read.table('bikes.txt', header=TRUE)
head(data)
D = ifelse(data$day=="No Holiday",1,0)
D
n = dim(data)[1]
n
data = cbind(data[,1:2], d = D)
head(data)
data
data <- read.table('bikes.txt', header=TRUE)
data
data <- read.table('bikes.txt', header=TRUE)
head(data)
D = ifelse(data$day=="No Holiday",1,0)
D
n = dim(data)[1]
n
data = cbind(data[,1:2], d = D)
head(data)
data
data <- read.table('bikes.txt', header=TRUE)
head(data)
D = ifelse(data$day=="No Holiday",1,0)
D
n = dim(data)[1]
n
data = cbind(data[,1:3], d = D)
head(data)
data
head(data)
fit <- lm(bike_count  ~ mean_temp + mean_wind + d + d:mean_temp + d:mean_wind)
summary(fit)
fit <- lm(bike_count  ~ mean_temp + mean_wind + d + d:mean_temp + d:mean_wind, data=data)
summary(fit)
sigma2 = sum(fit$residuals^2)/fit$df.residual
sigma2
n
fit$df.residual
50-6
sum(fit$residuals^2)
head(data)
range(data$bike_count)
8020*8020
par(mfrow=c(2,2))
plot(fit)
dev.off()
shapiro.test(fit$residuals)
linearHypothesis(fit, C1, b1)
C1 <- rbind(c(0,1,0,0,0,0),
c(0,0,1,0,0,0),
c(0,0,0,1,0,0),
c(0,0,0,0,1,0),
c(0,0,0,0,0,1))
b1 = c(0,0,0,0,0)
linearHypothesis(fit, C1, b1)
summary(fit)
C2 <- rbind(c(0,0,0,1,0,0),
c(0,0,0,0,1,0),
c(0,0,0,0,0,1))
b2 = c(0,0,0)
linearHypothesis(fit, C2, b2)
summary(fit)
C2
linearHypothesis(fit, C2, b2)
summary(fit)
par(mfrow=c(2,2))
plot(fit)
dev.off()
vif(fit)
fit2 <- lm(bike_count  ~ mean_temp + mean_wind + d + d:mean_temp +
d:mean_wind, data=data[-50,])
summary(fit2)
par(mfrow=c(2,2))
plot(fit2)
par(mfrow=c(2,2))
plot(fit)
fit2 <- lm(bike_count  ~ mean_temp + mean_wind + d + d:mean_temp +
d:mean_wind, data=data[c(-50,-32,-10),])
summary(fit2)
par(mfrow=c(2,2))
plot(fit2)
shapiro.test(fit2$residuals)
summary(fit)
C2 <- rbind(c(0,0,0,1,0,0),
c(0,0,0,0,1,0),
c(0,0,0,0,0,1),
c(0,0,1,0,0,0))
b2 = c(0,0,0,0)
linearHypothesis(fit, C2, b2)
C2 <- rbind(c(0,0,0,1,0,0),
c(0,0,0,0,1,0),
c(0,0,0,0,0,1))
b2 = c(0,0,0)
linearHypothesis(fit, C2, b2)
C2 <- rbind(c(0,0,0,0,1,0),
c(0,0,0,0,0,1))
b2 = c(0,0)
linearHypothesis(fit, C2, b2)
fit <- lm(bike_count  ~ mean_temp + mean_wind + d, data=data)
summary(fit)
fit3 <- lm(bike_count  ~ mean_temp + mean_wind + d, data=data)
summary(fit3)
fit <- lm(bike_count  ~ mean_temp + mean_wind + d + d:mean_temp + d:mean_wind, data=data)
summary(fit)
